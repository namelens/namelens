# NameLens v0.2.0 Release Notes

Release date: 2026-02-01

## Highlights

v0.2.0 is a feature release that completes the end-to-end naming workflow: from
idea generation through brand mark visualization. Key additions include bulk
expert analysis, brand mark generation, concurrent checks, and context
extraction for AI-powered workflows.

### Brand Mark Generation

New `namelens mark` command generates logo/brand mark concepts and images:

```bash
# Generate brand marks with context
namelens mark "myproject" --out-dir ./marks \
  --description "Static analysis tool for Go" \
  --audience "developers" \
  --color brand \
  --format png
```

- AI-generated images via OpenAI GPT Image models
- Color control: `monochrome`, `brand`, `vibrant` palettes
- Context-aware generation with `--description` and `--audience`
- Transparent background support for compositing

**Dogfooding success**: We used `namelens mark` to create the namelens icon,
validated through TinEye (0 matches across 80.9B images), and adopted it as our
official brand mark.
[Read the story →](../examples/namelens-brand-mark-story.md)

### Thumbnail Utility

New `namelens image thumb` creates agent-friendly thumbnails:

```bash
namelens image thumb --in-dir ./marks --max-size 256 --format jpeg
```

- Supports WebP, PNG, and JPEG input
- Configurable output size (64-1024px)
- Good for Slack/Discord sharing and AI agent workflows

### Bulk Expert Analysis

Check up to 10 names with a single AI call—reducing API costs and latency by
80-90% for shortlist triage:

```bash
# Screen 10 names with one AI request (default limit: 10)
namelens check envoyrelay conduitx nexusiq wardex sievex \
  --expert --expert-bulk --expert-depth=quick

# Custom batch size for larger shortlists
namelens check name1 name2 name3 name4 name5 name6 name7 \
  --expert --expert-bulk --expert-bulk-limit 7
```

**Why it matters**: Previously, checking 10 names required 10 separate AI calls.
Now it's 1 call with per-name results distributed automatically. Perfect for
early-stage screening before committing to deep analysis on finalists.

**Real-world impact**:

- Cost: 90% reduction in API calls for batch screening
- Time: 60-80% faster completion for multi-name checks
- Workflow: Triage 10 candidates in ~60 seconds vs ~300 seconds

### Concurrent Checks

Parallel domain and registry checking with configurable concurrency:

```bash
# Check 10 names with 5 concurrent workers
namelens check name1 name2 ... name10 \
  --tlds com,org,net --concurrency 5

# Recommended settings
# - RDAP TLDs (.com, .org, .net): --concurrency 3-5
# - WHOIS TLDs (.io, .sh, .co): --concurrency 1-2 (rate limits)
```

Each name's TLDs are checked in parallel up to the concurrency limit,
significantly reducing wall-clock time for large batches.

### Context Command

Extract and prepare corpus from project directories for AI workflows:

```bash
# Generate corpus for prompt inclusion
namelens context ./my-project --output=json > corpus.json

# Pipe directly to generate
namelens context ./planning | namelens generate "my product" --corpus=-

# Human-readable format for review
namelens context ./docs --output=markdown > review.md
```

The context command intelligently:

- Classifies files by type (README, architecture, decisions, planning)
- Allocates content budget by priority (25% readme, 20% architecture, etc.)
- Extracts metadata from project files (package.json, go.mod, etc.)
- Respects budget limits for AI prompt optimization

Perfect for feeding project documentation into `namelens generate` for
context-aware naming.

### AILink Request/Response Tracing

Debug provider issues with full interaction capture:

```bash
# Trace all AILink calls
namelens check myname --expert --trace /tmp/debug.ndjson

# Analyze the trace
jq 'select(.error) | {ts: .timestamp, error: .error}' /tmp/debug.ndjson
jq '.duration_ms' /tmp/debug.ndjson | jq -s 'add/length'  # Average latency
```

Trace files capture:

- Complete request bodies (prompts, tools, parameters)
- Full responses (content, tool calls, errors)
- Timing data (start, completion, duration)
- Token usage and cost metrics

Essential for debugging provider issues, auditing AI calls, and optimizing
prompts.

## New Commands and Flags

### Bulk Expert Mode

| Flag                  | Default | Description                                              |
| --------------------- | ------- | -------------------------------------------------------- |
| `--expert-bulk`       | false   | Enable bulk analysis (single AI call for multiple names) |
| `--expert-bulk-limit` | 10      | Maximum names per bulk request                           |

### Concurrent Checks

| Flag            | Default | Description                                 |
| --------------- | ------- | ------------------------------------------- |
| `--concurrency` | 3       | Parallel workers for domain/registry checks |

### Context Extraction

New `namelens context` command:

```bash
namelens context <directory> [flags]

Flags:
  --output, -o      Output format: json (default), markdown, prompt
  --budget          Max characters to include (default: 32000)
  --manifest-only   Show manifest without content
  --include         Additional glob patterns to include
```

### AILink Tracing

| Flag      | Default | Description                                               |
| --------- | ------- | --------------------------------------------------------- |
| `--trace` | ""      | Path to NDJSON file for tracing AILink requests/responses |

## Workflow Improvements

### Recommended Screening Workflow

**Phase 1: Bulk Triage** (v0.2.0 enhancement)

```bash
# Generate 20 candidates
namelens generate "concept" --depth deep > candidates.json

# Bulk screen top 10
namelens check name1 name2 ... name10 \
  --expert --expert-bulk --expert-depth=quick

# 60 seconds later: know which 3-5 are worth deep analysis
```

**Phase 2: Deep Analysis** (on finalists)

```bash
# Full brand analysis on top 3
namelens review finalist1 --depth=deep
namelens review finalist2 --depth=deep
namelens review finalist3 --depth=deep
```

**Phase 3: Visual Identity**

```bash
# Generate marks
namelens mark winner --out-dir ./marks --color brand

# Create thumbnails
namelens image thumb --in-dir ./marks
```

### Performance Benchmarks

Comparing v0.1.3 vs v0.2.0 for 10-name screening:

| Metric          | v0.1.3 | v0.2.0   | Improvement       |
| --------------- | ------ | -------- | ----------------- |
| Wall-clock time | ~300s  | ~60s     | **5x faster**     |
| AI API calls    | 10     | 1        | **10x fewer**     |
| Domain checks   | Serial | Parallel | **3-5x faster**   |
| Cost (tokens)   | 10x    | 1x       | **90% reduction** |

_Test conditions: 10 names, 3 TLDs (.com, .org, .net), quick expert depth_

## Technical Details

### Bulk Expert Architecture

The bulk expert feature uses a new AILink primitive:

```go
// Single request with multiple names
BulkSearchRequest {
  Names: ["name1", "name2", ...],
  Depth: "quick",
  // ... other params
}

// Response with per-name results
BulkSearchResponse {
  Summary: "Global notes",
  Items: [
    {Name: "name1", RiskLevel: "low", ...},
    {Name: "name2", RiskLevel: "medium", ...},
  ]
}
```

Results are automatically fanned out to per-name output for consistent CLI
experience.

### Concurrency Model

Domain checks now use a worker pool pattern:

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  Worker 1   │     │  Worker 2   │     │  Worker N   │
│  (TLD checks)│     │  (TLD checks)│     │  (TLD checks)│
└──────┬──────┘     └──────┬──────┘     └──────┬──────┘
       │                   │                   │
       └───────────────────┴───────────────────┘
                           │
                    ┌──────┴──────┐
                    │  Job Queue  │
                    │ (names)     │
                    └─────────────┘
```

Workers pull from a shared queue, with graceful shutdown on context
cancellation.

## Configuration

No breaking configuration changes. All v0.1.3 configurations remain valid.

New optional environment variables for brand mark generation:

```bash
# Route brand mark text and image generation separately
NAMELENS_AILINK_ROUTING_BRAND_MARK=namelens-openai
NAMELENS_AILINK_ROUTING_BRAND_MARK_IMAGE=namelens-openai-image

# Dedicated image provider (optional)
NAMELENS_AILINK_PROVIDERS_NAMELENS_OPENAI_IMAGE_ENABLED=true
NAMELENS_AILINK_PROVIDERS_NAMELENS_OPENAI_IMAGE_AI_PROVIDER=openai
NAMELENS_AILINK_PROVIDERS_NAMELENS_OPENAI_IMAGE_MODELS_IMAGE=gpt-image-1.5
```

### Provider Recommendations

| Provider         | Status       | Notes                                |
| ---------------- | ------------ | ------------------------------------ |
| OpenAI GPT Image | Recommended  | Best instruction following for marks |
| xAI grok-2-image | Experimental | No size/aspect control               |

## Security Updates

Transitive dependency updates addressing critical and high severity CVEs:

| Package  | Update            | Advisory            | Severity |
| -------- | ----------------- | ------------------- | -------- |
| x/crypto | v0.9.0 → v0.47.0  | GHSA-v778-237x-gjrc | Critical |
| x/crypto | v0.9.0 → v0.47.0  | GHSA-hcg3-q754-cr77 | High     |
| x/net    | v0.10.0 → v0.48.0 | GHSA-4374-p667-p6c8 | High     |
| x/sys    | v0.36.0 → v0.40.0 | (transitive)        | -        |
| testify  | v1.4.0 → v1.11.1  | removes yaml.v2     | High     |

See [SDR-001](../security/decisions/SDR-001-x-crypto-x-net-false-positives.md)
for analysis of scanner false positives from openrdap's declared requirements.

## Upgrade Notes

### From v0.1.3

1. **Binary update**:

   ```bash
   make build
   # or download from releases
   ```

2. **Verify installation**:

   ```bash
   namelens version  # Should show v0.2.0
   namelens doctor   # Should report healthy
   ```

3. **Test new features**:

   ```bash
   # Test bulk expert
   namelens check test1 test2 test3 --expert --expert-bulk

   # Test concurrency
   namelens check test1 test2 --concurrency 2

   # Test context
   namelens context . --manifest-only
   ```

### Migration Guide

No migration required. All existing:

- Configuration files work unchanged
- Cache databases remain compatible
- Scripts and workflows continue to function
- API integrations (if any) unaffected

## Documentation

- [Expert Search Guide](../user-guide/expert-search.md) - Updated for bulk mode
- [Context Command](../user-guide/context.md) - New corpus extraction
  documentation
- [Batch Operations](../user-guide/batch.md) - Concurrent check patterns
- [AILink Tracing](../ailink/README.md) - Debugging and transparency

## Known Limitations

- Bulk expert limit: Maximum 10 names per batch (configurable, but larger
  batches may hit provider token limits)
- Concurrency with WHOIS: High concurrency may trigger rate limits on
  WHOIS-heavy TLDs (.io, .sh, .co)
- Context budget: 32,000 char default may need adjustment for very large
  projects

## Acknowledgments

Thanks to our dogfooding team for validating bulk expert mode on real naming
projects including:

- seclusor (secrets management tool)
- mlvoy (email bridge project)
- hatsandhalos domain alternatives

The 5x performance improvement comes directly from real-world testing feedback.

---

Full changelog: [CHANGELOG.md](../../CHANGELOG.md)  
Release artifacts: GitHub Releases  
Docker: `ghcr.io/namelens/namelens:v0.2.0`
